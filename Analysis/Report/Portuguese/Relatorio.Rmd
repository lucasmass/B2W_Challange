---
title: "Relatório"
author: "Lucas Massaroppe"
date: "28/06/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Desafio B2W

Neste desafio foram consideradas duas bases de dados: (a) 'sales.csv' e (b) 'comp_prices.csv'. Em (a) consta informação transacional de nove produtos $P_i, i=1,\cdots,9$ para o ano de 2015 e em (b), contém dados de seis competidores $C_i, i=1,\cdots,6$, monitorados em horários diferentes, para as mesmas datas e produtos dos primeiros elementos.

Primeiramente analisaremos 'sales.csv' e, em uma segunda etapa, será dada atenção à 'comp_prices.csv', para que possamos assim fazer uma comparação entre as informações transacionais e os preços dos competidores.

# Base 'sales.csv'

Como uma verificação rápida apresentamos as séries temporais dos nove produtos na Figura \ref{fig:fig1}. Assim, podemos realizar o teste KPSS sobre cada uma delas a fim de saber se elas possuem raiz unitaria e tendência, ou seja, se são ou não estacionárias.

A tabela abaixo apresenta os resultados do teste KPSS.

\begin{center}
  \begin{tabular}{ c | c | c }
    Produto & Estatística & $p$-valor \\ \hline\hline
    $P_1$   & $0,\!14$    & $0,\!07$  \\  
    $P_2$   & $0,\!17$    & $0,\!02$  \\
    $P_3$   & $0,\!53$    & $<0,\!01$ \\
    $P_4$   & $0,\!04$    & $>0,\!10$ \\
    $P_5$   & $0,\!26$    & $<0,\!01$ \\
    $P_6$   & $0,\!08$    & $>0,\!10$ \\
    $P_7$   & $0,\!42$    & $<0,\!01$ \\
    $P_8$   & $0,\!09$    & $>0,\!10$ \\
    $P_9$   & $0,\!06$    & $>0,\!10$ \\
  \end{tabular}
\end{center}

Note que, de acordo com a hipótese nula do teste KPSS e utilizando um nível de significância $\alpha=1\%$, as séries dos produtos que apresentam $p$-valor menor do $\alpha$ são estacionárias, ou seja, $P_3, P_5 \ \mbox{e} \ P_7$.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig1}Preço médio dos produtos."}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tseries))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(dplyr))

# Reading CSV file
data.sales <- read.csv(file = "./sales.csv",
                        head = TRUE, 
                        dec = ".", 
                        sep = ",", 
                        na.strings = "")

# Date as charecter string
datime <- as.character(data.sales$DATE_ORDER)

# Order the data by product id and date and then take the mean value of the prices (revenue), regarding products quantity
ordered_data <- data.sales %>% 
  group_by(PROD_ID, DATE_ORDER) %>% 
  summarise(REVENUE = mean(REVENUE)) 

# Separate the products time series, regardless the payment type and the competitors
P1.data <- subset(ordered_data, ordered_data$PROD_ID == "P1")
P2.data <- subset(ordered_data, ordered_data$PROD_ID == "P2")
P3.data <- subset(ordered_data, ordered_data$PROD_ID == "P3")
P4.data <- subset(ordered_data, ordered_data$PROD_ID == "P4")
P5.data <- subset(ordered_data, ordered_data$PROD_ID == "P5")
P6.data <- subset(ordered_data, ordered_data$PROD_ID == "P6")
P7.data <- subset(ordered_data, ordered_data$PROD_ID == "P7")
P8.data <- subset(ordered_data, ordered_data$PROD_ID == "P8")
P9.data <- subset(ordered_data, ordered_data$PROD_ID == "P9")

# Plot the time series to a quick check
par(mfrow = c(3, 3))
plot.ts(P1.data$REVENUE, xlim = c(0, length(P1.data$REVENUE)), col = "blue", ylab = "", main = "P1 Revenue")
plot.ts(P2.data$REVENUE, xlim = c(0, length(P2.data$REVENUE)), col = "blue", ylab = "", main = "P2 Revenue")
plot.ts(P3.data$REVENUE, xlim = c(0, length(P3.data$REVENUE)), col = "blue", ylab = "", main = "P3 Revenue")
plot.ts(P4.data$REVENUE, xlim = c(0, length(P4.data$REVENUE)), col = "blue", ylab = "", main = "P4 Revenue")
plot.ts(P5.data$REVENUE, xlim = c(0, length(P5.data$REVENUE)), col = "blue", ylab = "", main = "P5 Revenue")
plot.ts(P6.data$REVENUE, xlim = c(0, length(P6.data$REVENUE)), col = "blue", ylab = "", main = "P6 Revenue")
plot.ts(P7.data$REVENUE, xlim = c(0, length(P7.data$REVENUE)), col = "blue", ylab = "", main = "P7 Revenue")
plot.ts(P8.data$REVENUE, xlim = c(0, length(P8.data$REVENUE)), col = "blue", ylab = "", main = "P8 Revenue")
plot.ts(P9.data$REVENUE, xlim = c(0, length(P9.data$REVENUE)), col = "blue", ylab = "", main = "P9 Revenue")
```

# Previsão das séries dos produtos

Para todas as séries temporais utilizamos três modelos de previsões: o linear ARIMA$(p,d,q)$, o não-linear de suavização exponencial ETS e o de rede neural autorregresivo NNETAR$(p,k)$. Para avaliar qual o melhor modelo entre os três, utilizamos o desvio padrão dos resíduos como métrica de comparação e mostramos na tabela a seguir.

\begin{center}
  \begin{tabular}{ c | c | c | c }
    Produto & ARIMA$(p,d,q)$                                    & ETS                                               & NNETAR$(p,k)$                                  \\ \hline\hline
    $P_1$   & ARIMA$(1,1,1)$, $\widehat{\sigma_{e}} =  66,\!87$ & ETS$(M,N,N)$,   $\widehat{\sigma_{e}} =   0,\!04$ & NNETAR$(4,2)$, $\widehat{\sigma_{e}} = 0,\!04$ \\  
    $P_2$   & ARIMA$(0,1,2)$, $\widehat{\sigma_{e}} =  32,\!21$ & ETS$(A,N,N)$,   $\widehat{\sigma_{e}} =  33,\!56$ & NNETAR$(7,4)$, $\widehat{\sigma_{e}} = 0,\!04$ \\
    $P_3$   & ARIMA$(2,1,3)$, $\widehat{\sigma_{e}} =  71,\!28$ & ETS$(A,N,N)$,   $\widehat{\sigma_{e}} =  72,\!13$ & NNETAR$(7,4)$, $\widehat{\sigma_{e}} = 0,\!05$ \\
    $P_4$   & ARIMA$(0,0,0)$, $\widehat{\sigma_{e}} = 436,\!59$ & ETS$(A,N,N)$,   $\widehat{\sigma_{e}} = 437,\!72$ & NNETAR$(1,1)$, $\widehat{\sigma_{e}} = 0,\!22$ \\
    $P_5$   & ARIMA$(0,1,1)$, $\widehat{\sigma_{e}} = 109,\!04$ & ETS$(M,N,N)$,   $\widehat{\sigma_{e}} =   0,\!11$ & NNETAR$(4,2)$, $\widehat{\sigma_{e}} = 0,\!08$ \\
    $P_6$   & ARIMA$(5,1,0)$, $\widehat{\sigma_{e}} = 231,\!71$ & ETS$(M,A_d,N)$, $\widehat{\sigma_{e}} =   0,\!12$ & NNETAR$(6,4)$, $\widehat{\sigma_{e}} = 0,\!05$ \\
    $P_7$   & ARIMA$(0,1,1)$, $\widehat{\sigma_{e}} =  34,\!35$ & ETS$(A,N,N)$,   $\widehat{\sigma_{e}} =  34,\!37$ & NNETAR$(8,4)$, $\widehat{\sigma_{e}} = 0,\!03$ \\
    $P_8$   & ARIMA$(2,1,1)$, $\widehat{\sigma_{e}} =  29,\!99$ & ETS$(M,N,N)$,   $\widehat{\sigma_{e}} =   0,\!05$ & NNETAR$(2,2)$, $\widehat{\sigma_{e}} = 0,\!03$ \\
    $P_9$   & ARIMA$(1,1,1)$, $\widehat{\sigma_{e}} =  39,\!47$ & ETS$(M,N,N)$,   $\widehat{\sigma_{e}} =   0,\!08$ & NNETAR$(6,4)$, $\widehat{\sigma_{e}} = 0,\!06$ \\
  \end{tabular}
\end{center}

Portanto, pela tabela anterior, é possível concluir que o melhor modelo em todos casos é o NNETAR$(p,k)$, pois
\[\widehat{\sigma_{e}}_{\mbox{NNETAR$(p,k)$}} < \widehat{\sigma_{e}}_{\mbox{ETS}} < \widehat{\sigma_{e}}_{\mbox{ARIMA$(p,d,q)$}},\]
em que se pode escrever o modelo NNETAR$(p,k)$ da seguinte forma,
\[ x(n) = f \left( \sum_{r=1}^{p} \boldsymbol{\Phi}_{r} \mathbf{x}(n-r) \right) + e(n), \]
em que, da rede neural, tem-se que, $\mathbf{x}(n-r)$ é um vetor $k \times 1$ com as respectivas entradas, $\boldsymbol{\Phi}_{r}$ sd matrizes de parâmetros de dimensão $k \times k$, $k$ o numero de camadas, $f(\cdot)$ a função de ativação (que, no caso, é a sigmóide) e $e(n)$ um processo independente, identicamente distributído, de média nula e variância $\sigma_{e}^{2}$ ($\{e(n)\}_{n \in \mathbb{Z}} \sim$ i.i.d.$(0, \sigma_e^2)$).

Porém, pela experiência prévia de manipulação de dados anuais do candidato e modelos NNETAR$(p,k)$ é necessário se modificar os parâmetros $p$ e $k$ dos modelos dos produtos $P_i, i = 1, \cdots, 9$, para que os mesmos sejam capazes de capturar a dinâmica não-linear dos processos.

Assim, como se trata de dados anuais e apesar de se possuir apenas um ano de dados, para ambos os parâmetros utilizam-se múltiplos de $12$, ou seja $p=k=24$ para que se possa ter a restrição de o moelo conseguir capturar anualidade.
             
De fato, observe que na próxima tabela os valores de \(\widehat{\sigma_{e}}_{\mbox{NNETAR$(p,k)$}}\) diminuem em todos os casos.

\begin{center}
  \begin{tabular}{ c | c }
    Produto & NNETAR$(24,24)$                                \\ \hline\hline
    $P_1$   & $\widehat{\sigma_{e}} = 2,\!83 \times 10^{-5}$ \\  
    $P_2$   & $\widehat{\sigma_{e}} = 1,\!08 \times 10^{-4}$ \\
    $P_3$   & $\widehat{\sigma_{e}} = 2,\!32 \times 10^{-4}$ \\
    $P_4$   & $\widehat{\sigma_{e}} = 1,\!81 \times 10^{-4}$ \\
    $P_5$   & $\widehat{\sigma_{e}} = 9,\!82 \times 10^{-5}$ \\
    $P_6$   & $\widehat{\sigma_{e}} = 1,\!17 \times 10^{-2}$ \\
    $P_7$   & $\widehat{\sigma_{e}} = 1,\!38 \times 10^{-3}$ \\
    $P_8$   & $\widehat{\sigma_{e}} = 7,\!36 \times 10^{-5}$ \\
    $P_9$   & $\widehat{\sigma_{e}} = 8,\!32 \times 10^{-5}$ \\
  \end{tabular}
\end{center}

Na Figura \ref{fig:fig2} a seguir, mostra-se a previsão realizada por esses modelos.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig2}Previsão dos preços médios dos produtos para os próximos 30 dias."}
   suppressPackageStartupMessages(library(fpp2))
   suppressPackageStartupMessages(library(gridExtra))
 
   # Reading CSV file
   data.sales <- read.csv(file = "./sales.csv",
                           head = TRUE,
                           dec = ".",
                           sep = ",",
                           na.strings = "")
   # Date as charecter string# datime <- as.character(data.sales$DATE_ORDER)#
   # Order the data by product id and date and then take the mean value of the prices (revenue), regarding products quantity
   ordered_data <- data.sales %>%
     group_by(PROD_ID, DATE_ORDER) %>%
     summarise(REVENUE = mean(REVENUE))
 
                P1 <- ts(P1.data$REVENUE)
     fit.nnetar.P1 <- nnetar(P1, 24, 0, 24, lambda = 0)
   fcast.nnetar.P1 <- forecast(fit.nnetar.P1, PI = TRUE, h = 30)
 
                P2 <- ts(P2.data$REVENUE)
     fit.nnetar.P2 <- nnetar(P2, 24, 0, 24, lambda = 0)
   fcast.nnetar.P2 <- forecast(fit.nnetar.P2, PI = TRUE, h = 30)
 
                P3 <- ts(P3.data$REVENUE)
     fit.nnetar.P3 <- nnetar(P3, 24, 0, 24, lambda = 0)
   fcast.nnetar.P3 <- forecast(fit.nnetar.P3, PI = TRUE, h = 30)
 
                P4 <- ts(P4.data$REVENUE)
     fit.nnetar.P4 <- nnetar(P4, 24, 0, 24, lambda = 0)
   fcast.nnetar.P4 <- forecast(fit.nnetar.P4, PI = TRUE, h = 30)
 
                P5 <- ts(P5.data$REVENUE)
     fit.nnetar.P5 <- nnetar(P5, 24, 0, 24, lambda = 0)
   fcast.nnetar.P5 <- forecast(fit.nnetar.P5, PI = TRUE, h = 30)
 
                P6 <- ts(P6.data$REVENUE)
     fit.nnetar.P6 <- nnetar(P6, 24, 0, 24, lambda = 0)
   fcast.nnetar.P6 <- forecast(fit.nnetar.P6, PI = TRUE, h = 30)
 
                P7 <- ts(P7.data$REVENUE)
     fit.nnetar.P7 <- nnetar(P7, 24, 0, 24, lambda = 0)
   fcast.nnetar.P7 <- forecast(fit.nnetar.P7, PI = TRUE, h = 30)
 
                P8 <- ts(P8.data$REVENUE)
     fit.nnetar.P8 <- nnetar(P8, 24, 0, 24, lambda = 0)
   fcast.nnetar.P8 <- forecast(fit.nnetar.P8, PI = TRUE, h = 30)
 
                P9 <- ts(P9.data$REVENUE)
     fit.nnetar.P9 <- nnetar(P9, 24, 0, 24, lambda = 0)
   fcast.nnetar.P9 <- forecast(fit.nnetar.P9, PI = TRUE, h = 30)
 
   #par(mfrow = c(3, 3))
   p1 <- autoplot(fcast.nnetar.P1, include = 20) + ggtitle("")
   p2 <- autoplot(fcast.nnetar.P2, include = 20) + ggtitle("")
   p3 <- autoplot(fcast.nnetar.P3, include = 20) + ggtitle("")
   p4 <- autoplot(fcast.nnetar.P4, include = 20) + ggtitle("")
   p5 <- autoplot(fcast.nnetar.P5, include = 20) + ggtitle("")
   p6 <- autoplot(fcast.nnetar.P6, include = 20) + ggtitle("")
   p7 <- autoplot(fcast.nnetar.P7, include = 20) + ggtitle("")
   p8 <- autoplot(fcast.nnetar.P8, include = 20) + ggtitle("")
   p9 <- autoplot(fcast.nnetar.P9, include = 20) + ggtitle("")
   grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, nrow = 3)
```

Na seção seguinte mostra-se o caso para os dados dos competidores.

# Base 'comp_prices.csv'

Para os dados da base 'comp_prices.csv' fez-se necessário realizar uma redução de dimensionalidade.

Primeiramente, agrupou-se os dados em relação à forma de pagamento, ou seja, à prazo ou à vista, obtendo-se os gráficos da Figura \ref{fig:fig3}. Assim, como se observa nessa figura, percebe-se que não há diferença entre as formas de pagamentos e podemos classficar as variáveis independente desta que estamos analisando.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig3}Tipo de pagamento dos competidores."}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tseries))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(dplyr))

# Reading CSV file
data.comp  <- read.csv(file = "comp_prices.csv", 
                       head = TRUE, 
                       dec = ".", 
                       sep = ",", 
                       na.strings = "")

# Separate date and time, from DATE_EXTRACTION variable
datime <- do.call(rbind, strsplit(as.character(data.comp$DATE_EXTRACTION), " "))

##################################################
# Dimensionality reduction
##################################################

###
### Investigating the importance of PAY_TYPE variable
###

# Group the data by payment type, product id, date and time and then take the mean value of the prices, regardless the competitors and products
ordered_data_pay <- data.comp %>% 
  group_by(PAY_TYPE, DATE_ORDER = datime[,1], HOUR_ORDER = datime[,2]) %>% 
  summarise(COMPETITOR_PRICE =  mean(COMPETITOR_PRICE))

# Order the data by period of the day: nocturnal (N --- 12pm -- 12am) and diurnal (D --- 12am -- 12pm)
ordered_data_pay$period <- rep("N", nrow(ordered_data_pay))
ordered_data_pay$period[ordered_data_pay$HOUR_ORDER < '12:00'] <- "D"

# Separate the payment type time series, regardless the competitors and products
PAY1.data   <- subset(ordered_data_pay, ordered_data_pay$PAY_TYPE == 1)
PAY1.data.D <- subset(PAY1.data, PAY1.data$period == "D")
PAY1.data.N <- subset(PAY1.data, PAY1.data$period == "N")

PAY2.data   <- subset(ordered_data_pay, ordered_data_pay$PAY_TYPE == 2)
PAY2.data.D <- subset(PAY2.data, PAY2.data$period == "D")
PAY2.data.N <- subset(PAY2.data, PAY2.data$period == "N")

# Plot the time series to a quick check if the diurnal (D) or nocturnal (N) periods are too different from each other
par(mfrow = c(2, 1))

plot.ts(PAY1.data.D$COMPETITOR_PRICE, ylim = c( 690, 1900), xlim = c(0, length(PAY1.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "Deferred Payment")
par(new = TRUE)
plot.ts(PAY1.data.N$COMPETITOR_PRICE, ylim = c( 690, 1900), xlim = c(0, length(PAY1.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(PAY2.data.D$COMPETITOR_PRICE, ylim = c( 690, 1900), xlim = c(0, length(PAY2.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "Immediate Payment")
par(new = TRUE)
plot.ts(PAY2.data.N$COMPETITOR_PRICE, ylim = c( 690, 1900), xlim = c(0, length(PAY2.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")
```

Já para investigar a importância de cada competidor, é importante aglomerar as variáveis acima e organizá-las indiferentemente dos produtos, porém mantendo ordem temporal, obtendo-se a Figura \ref{fig:fig4}.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig4}Pagamentos segundo os competidores e períodos diúrno (linha azul) e noturno (linha vermelha)."}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tseries))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(dplyr))

suppressPackageStartupMessages(library("GGally"))

# Reading CSV file
data.comp  <- read.csv(file = "comp_prices.csv", 
                       head = TRUE, 
                       dec = ".", 
                       sep = ",", 
                       na.strings = "")

# Separate date and time, from DATE_EXTRACTION variable
datime <- do.call(rbind, strsplit(as.character(data.comp$DATE_EXTRACTION), " "))

##################################################
# Dimensionality reduction
##################################################

###
### Investigating the importance of COMPETITOR variable
###

# Group the data by competitor, date and time and then take the mean value of the prices, regardless the competitors and product id
ordered_data_comp <- data.comp %>% 
  group_by(COMPETITOR, DATE_ORDER = datime[,1], HOUR_ORDER = datime[,2]) %>% 
  summarise(COMPETITOR_PRICE =  mean(COMPETITOR_PRICE))

# Order the data by period of the day: nocturnal (N --- 12pm -- 12am) and diurnal (D --- 12am -- 12pm)
ordered_data_comp$period <- rep("N", nrow(ordered_data_comp))
ordered_data_comp$period[ordered_data_comp$HOUR_ORDER < '12:00'] <- "D"

# Separate the competitors time series, regardless the payment type and the products
C1.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C1")
C1.data.D <- subset(C1.data, C1.data$period == "D")
C1.data.N <- subset(C1.data, C1.data$period == "N")

C2.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C2")
C2.data.D <- subset(C2.data, C2.data$period == "D")
C2.data.N <- subset(C2.data, C2.data$period == "N")

C3.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C3")
C3.data.D <- subset(C3.data, C3.data$period == "D")
C3.data.N <- subset(C3.data, C3.data$period == "N")

C4.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C4")
C4.data.D <- subset(C4.data, C4.data$period == "D")
C4.data.N <- subset(C4.data, C4.data$period == "N")

C5.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C5")
C5.data.D <- subset(C5.data, C5.data$period == "D")
C5.data.N <- subset(C5.data, C5.data$period == "N")

C6.data   <- subset(ordered_data_comp, ordered_data_comp$COMPETITOR == "C6")
C6.data.D <- subset(C6.data, C6.data$period == "D")
C6.data.N <- subset(C6.data, C6.data$period == "N")

# Plot the time series to a quick check if the diurnal (D) or nocturnal (N) periods are too different from each other
par(mfrow = c(2, 3))

plot.ts(C1.data.D$COMPETITOR_PRICE, ylim = c( 550, 2400), xlim = c(0, length(C1.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C1 Mean Price")
par(new = TRUE)
plot.ts(C1.data.N$COMPETITOR_PRICE, ylim = c( 550, 2400), xlim = c(0, length(C1.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(C2.data.D$COMPETITOR_PRICE, ylim = c( 570, 2200), xlim = c(0, length(C2.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C2 Mean Price")
par(new = TRUE)
plot.ts(C2.data.N$COMPETITOR_PRICE, ylim = c( 570, 2200), xlim = c(0, length(C2.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(C3.data.D$COMPETITOR_PRICE, ylim = c( 450, 2000), xlim = c(0, length(C3.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C3 Mean Price")
par(new = TRUE)
plot.ts(C3.data.N$COMPETITOR_PRICE, ylim = c( 450, 2000), xlim = c(0, length(C3.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(C4.data.D$COMPETITOR_PRICE, ylim = c( 420, 1600), xlim = c(0, length(C4.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C4 Mean Price")
par(new = TRUE)
plot.ts(C4.data.N$COMPETITOR_PRICE, ylim = c( 420, 1600), xlim = c(0, length(C4.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(C5.data.D$COMPETITOR_PRICE, ylim = c( 450, 1550), xlim = c(0, length(C5.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C5 Mean Price")
par(new = TRUE)
plot.ts(C5.data.N$COMPETITOR_PRICE, ylim = c( 450, 1550), xlim = c(0, length(C5.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(C6.data.D$COMPETITOR_PRICE, ylim = c( 510, 2800), xlim = c(0, length(C6.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "C6 Mean Price")
par(new = TRUE)
plot.ts(C6.data.N$COMPETITOR_PRICE, ylim = c( 510, 2800), xlim = c(0, length(C6.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

```

Pela Figura \ref{fig:fig4}, percebe-se que não há diferenciação entre os períodos diurnos (linha azul) e noturno (linha vermelha) para todos os competidores. Logo, daqui para frente não será feita diferenciação entre essas variáveis (ou seja, $C_i, i=1, \cdots, 6$).

A seguir, mostra-se as séries temporais dos produtos aglomerados independentemente dos competidores.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig4}Séries dos produtos, mostrando os períodos diúrno (linha azul) e noturno (linha vermelha)."}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tseries))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(dplyr))

suppressPackageStartupMessages(library("GGally"))

# Reading CSV file
data.comp  <- read.csv(file = "comp_prices.csv", 
                       head = TRUE, 
                       dec = ".", 
                       sep = ",", 
                       na.strings = "")

# Separate date and time, from DATE_EXTRACTION variable
datime <- do.call(rbind, strsplit(as.character(data.comp$DATE_EXTRACTION), " "))

##################################################
# Dimensionality reduction
##################################################

###
### Investigating the importance of COMPETITOR variable
###

###
### As the aforementioned analysis tells us the variables PAY_TYPE and COMPETITOR are not that different
### during the defined diurnal shift (D --- 12am - 12pm) and nocturnal (N --- 12pm - 12am)
### Therefore, as a grouping variable we will use PROD_ID, regardless PAY_TYPE and COMPETITORS variables
###

# Group the data by product id, date and time and then take the mean value of the prices, regardless the competitors
ordered_data <- data.comp %>% 
  group_by(PROD_ID, DATE_ORDER = datime[,1], HOUR_ORDER = datime[,2]) %>% 
  summarise(COMPETITOR_PRICE =  mean(COMPETITOR_PRICE))

# Order the data by period of the day: nocturnal (N --- 12pm - 12am) and diurnal (D --- 12am - 12pm)
ordered_data$period <- rep("N", nrow(ordered_data))
ordered_data$period[ordered_data$HOUR_ORDER < '12:00'] <- "D"

# Separate the products time series, regardless the payment type and the competitors
P1.data   <- subset(ordered_data, ordered_data$PROD_ID == "P1")
P1.data.D <- subset(P1.data, P1.data$period == "D")
P1.data.N <- subset(P1.data, P1.data$period == "N")

P2.data   <- subset(ordered_data, ordered_data$PROD_ID == "P2")
P2.data.D <- subset(P2.data, P2.data$period == "D")
P2.data.N <- subset(P2.data, P2.data$period == "N")

P3.data   <- subset(ordered_data, ordered_data$PROD_ID == "P3")
P3.data.D <- subset(P3.data, P3.data$period == "D")
P3.data.N <- subset(P3.data, P3.data$period == "N")

P4.data   <- subset(ordered_data, ordered_data$PROD_ID == "P4")
P4.data.D <- subset(P4.data, P4.data$period == "D")
P4.data.N <- subset(P4.data, P4.data$period == "N")

P5.data   <- subset(ordered_data, ordered_data$PROD_ID == "P5")
P5.data.D <- subset(P5.data, P5.data$period == "D")
P5.data.N <- subset(P5.data, P5.data$period == "N")

P6.data   <- subset(ordered_data, ordered_data$PROD_ID == "P6")
P6.data.D <- subset(P6.data, P6.data$period == "D")
P6.data.N <- subset(P6.data, P6.data$period == "N")

P7.data   <- subset(ordered_data, ordered_data$PROD_ID == "P7")
P7.data.D <- subset(P7.data, P7.data$period == "D")
P7.data.N <- subset(P7.data, P7.data$period == "N")

P8.data   <- subset(ordered_data, ordered_data$PROD_ID == "P8")
P8.data.D <- subset(P8.data, P8.data$period == "D")
P8.data.N <- subset(P8.data, P8.data$period == "N")

P9.data   <- subset(ordered_data, ordered_data$PROD_ID == "P9")
P9.data.D <- subset(P9.data, P9.data$period == "D")
P9.data.N <- subset(P9.data, P9.data$period == "N")

# Plot the time series to a quick check if the diurnal (D) or nocturnal (N) periods are too different from each other
# If not, just take the mean value between the series and forecast them
par(mfrow = c(3, 3))

plot.ts(P1.data.D$COMPETITOR_PRICE, ylim = c(1000, 2000), xlim = c(0, length(P1.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P1 Mean Price")
par(new = TRUE)
plot.ts(P1.data.N$COMPETITOR_PRICE, ylim = c(1000, 2000), xlim = c(0, length(P1.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P2.data.D$COMPETITOR_PRICE, ylim = c( 600,  850), xlim = c(0, length(P2.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P2 Mean Price")
par(new = TRUE)
plot.ts(P2.data.N$COMPETITOR_PRICE, ylim = c( 600,  850), xlim = c(0, length(P2.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P3.data.D$COMPETITOR_PRICE, ylim = c( 880, 1500), xlim = c(0, length(P3.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P3 Mean Price")
par(new = TRUE)
plot.ts(P3.data.N$COMPETITOR_PRICE, ylim = c( 880, 1500), xlim = c(0, length(P3.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P4.data.D$COMPETITOR_PRICE, ylim = c( 400,  700), xlim = c(0, length(P4.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P4 Mean Price")
par(new = TRUE)
plot.ts(P4.data.N$COMPETITOR_PRICE, ylim = c( 400,  700), xlim = c(0, length(P4.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P5.data.D$COMPETITOR_PRICE, ylim = c( 700, 1100), xlim = c(0, length(P5.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P5 Mean Price")
par(new = TRUE)
plot.ts(P5.data.N$COMPETITOR_PRICE, ylim = c( 700, 1100), xlim = c(0, length(P5.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P6.data.D$COMPETITOR_PRICE, ylim = c(1400, 2400), xlim = c(0, length(P6.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P6 Mean Price")
par(new = TRUE)
plot.ts(P6.data.N$COMPETITOR_PRICE, ylim = c(1400, 2400), xlim = c(0, length(P6.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P7.data.D$COMPETITOR_PRICE, ylim = c( 680, 1000), xlim = c(0, length(P7.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P7 Mean Price")
par(new = TRUE)
plot.ts(P7.data.N$COMPETITOR_PRICE, ylim = c( 680, 1000), xlim = c(0, length(P7.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P8.data.D$COMPETITOR_PRICE, ylim = c( 380,  550), xlim = c(0, length(P8.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P8 Mean Price")
par(new = TRUE)
plot.ts(P8.data.N$COMPETITOR_PRICE, ylim = c( 380,  550), xlim = c(0, length(P8.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")

plot.ts(P9.data.D$COMPETITOR_PRICE, ylim = c( 400,  550), xlim = c(0, length(P9.data.D$COMPETITOR_PRICE)), col = "blue", ylab = "P9 Mean Price")
par(new = TRUE)
plot.ts(P9.data.N$COMPETITOR_PRICE, ylim = c( 400,  550), xlim = c(0, length(P9.data.D$COMPETITOR_PRICE)), col = "red",  ylab = "")
```

Como percebe-se, aqui não diferenciação entre os períodos do dia e, portanto, para se obter apenas uma série por produto, utilizou-se a média entre os diúrnos e noturno, para se poder fazer a previsão dos preços como é mostrado na Figura \ref{fig:fig5}, a seguir.

```{r, echo = FALSE, fig.width = 7, fig.height = 6, fig.cap = "\\label{fig:fig5}Previsão dos preços médios dos produtos dos competidores para os próximos 30 dias."}
   suppressPackageStartupMessages(library(fpp2))
   suppressPackageStartupMessages(library(gridExtra))

   # Reading CSV file
data.comp  <- read.csv(file = "comp_prices.csv", 
                        head = TRUE, 
                        dec = ".", 
                        sep = ",", 
                        na.strings = "")

# Separate date and time, from DATE_EXTRACTION variable
datime <- do.call(rbind, strsplit(as.character(data.comp$DATE_EXTRACTION), " "))

# Group the data by product id, date and time and then take the mean value of the prices, regardless the competitors
ordered_data <- data.comp %>% 
  group_by(PROD_ID, DATE_ORDER = datime[,1], HOUR_ORDER = datime[,2]) %>% 
  summarise(COMPETITOR_PRICE =  mean(COMPETITOR_PRICE))

# Order the data by period of the day: nocturnal (N --- 12pm - 12am) and diurnal (D --- 12am - 12pm)
ordered_data$period <- rep("N", nrow(ordered_data))
ordered_data$period[ordered_data$HOUR_ORDER < '12:00'] <- "D"

# Separate the products time series, regardless the payment type and the competitors
P1.data   <- subset(ordered_data, ordered_data$PROD_ID == "P1")
P1.data.D <- subset(P1.data, P1.data$period == "D")
P1.data.N <- subset(P1.data, P1.data$period == "N")

P2.data   <- subset(ordered_data, ordered_data$PROD_ID == "P2")
P2.data.D <- subset(P2.data, P2.data$period == "D")
P2.data.N <- subset(P2.data, P2.data$period == "N")

P3.data   <- subset(ordered_data, ordered_data$PROD_ID == "P3")
P3.data.D <- subset(P3.data, P3.data$period == "D")
P3.data.N <- subset(P3.data, P3.data$period == "N")

P4.data   <- subset(ordered_data, ordered_data$PROD_ID == "P4")
P4.data.D <- subset(P4.data, P4.data$period == "D")
P4.data.N <- subset(P4.data, P4.data$period == "N")

P5.data   <- subset(ordered_data, ordered_data$PROD_ID == "P5")
P5.data.D <- subset(P5.data, P5.data$period == "D")
P5.data.N <- subset(P5.data, P5.data$period == "N")

P6.data   <- subset(ordered_data, ordered_data$PROD_ID == "P6")
P6.data.D <- subset(P6.data, P6.data$period == "D")
P6.data.N <- subset(P6.data, P6.data$period == "N")

P7.data   <- subset(ordered_data, ordered_data$PROD_ID == "P7")
P7.data.D <- subset(P7.data, P7.data$period == "D")
P7.data.N <- subset(P7.data, P7.data$period == "N")

P8.data   <- subset(ordered_data, ordered_data$PROD_ID == "P8")
P8.data.D <- subset(P8.data, P8.data$period == "D")
P8.data.N <- subset(P8.data, P8.data$period == "N")

P9.data   <- subset(ordered_data, ordered_data$PROD_ID == "P9")
P9.data.D <- subset(P9.data, P9.data$period == "D")
P9.data.N <- subset(P9.data, P9.data$period == "N")

##################################################
# Forecasting Procedure
##################################################

# Data preparation to forecasting procedure

                Y1 <- ts(P1.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P1.data.N$COMPETITOR_PRICE)
                P1 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P1 <- nnetar(P1, 24, 0, 24, lambda = 0)
   fcast.nnetar.P1 <- forecast(fit.nnetar.P1, PI = TRUE, h = 30)

                Y1 <- ts(P2.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P2.data.N$COMPETITOR_PRICE)
                P2 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P2 <- nnetar(P2, 24, 0, 24, lambda = 0)
   fcast.nnetar.P2 <- forecast(fit.nnetar.P2, PI = TRUE, h = 30)

                Y1 <- ts(P3.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P3.data.N$COMPETITOR_PRICE)
                P3 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P3 <- nnetar(P3, 24, 0, 24, lambda = 0)
   fcast.nnetar.P3 <- forecast(fit.nnetar.P3, PI = TRUE, h = 30)

                Y1 <- ts(P4.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P4.data.N$COMPETITOR_PRICE)
                P4 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P4 <- nnetar(P4, 24, 0, 24, lambda = 0)
   fcast.nnetar.P4 <- forecast(fit.nnetar.P4, PI = TRUE, h = 30)

                Y1 <- ts(P5.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P5.data.N$COMPETITOR_PRICE)
                P5 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P5 <- nnetar(P5, 24, 0, 24, lambda = 0)
   fcast.nnetar.P5 <- forecast(fit.nnetar.P5, PI = TRUE, h = 30)

                Y1 <- ts(P6.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P6.data.N$COMPETITOR_PRICE)
                P6 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P6 <- nnetar(P6, 24, 0, 24, lambda = 0)
   fcast.nnetar.P6 <- forecast(fit.nnetar.P6, PI = TRUE, h = 30)

                Y1 <- ts(P7.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P7.data.N$COMPETITOR_PRICE)
                P7 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P7 <- nnetar(P7, 24, 0, 24, lambda = 0)
   fcast.nnetar.P7 <- forecast(fit.nnetar.P7, PI = TRUE, h = 30)

                Y1 <- ts(P8.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P8.data.N$COMPETITOR_PRICE)
                P8 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P8 <- nnetar(P8, 24, 0, 24, lambda = 0)
   fcast.nnetar.P8 <- forecast(fit.nnetar.P8, PI = TRUE, h = 30)

                Y1 <- ts(P9.data.D$COMPETITOR_PRICE)
                Y2 <- ts(P9.data.N$COMPETITOR_PRICE)
                P9 <- cbind(Y1, Y2) %>% rowMeans() %>% na.omit() %>% ts()
     fit.nnetar.P9 <- nnetar(P9, 24, 0, 24, lambda = 0)
   fcast.nnetar.P9 <- forecast(fit.nnetar.P9, PI = TRUE, h = 30)

   #par(mfrow = c(3, 3))
   p1 <- autoplot(fcast.nnetar.P1, include = 20) + ggtitle("")
   p2 <- autoplot(fcast.nnetar.P2, include = 20) + ggtitle("")
   p3 <- autoplot(fcast.nnetar.P3, include = 20) + ggtitle("")
   p4 <- autoplot(fcast.nnetar.P4, include = 20) + ggtitle("")
   p5 <- autoplot(fcast.nnetar.P5, include = 20) + ggtitle("")
   p6 <- autoplot(fcast.nnetar.P6, include = 20) + ggtitle("")
   p7 <- autoplot(fcast.nnetar.P7, include = 20) + ggtitle("")
   p8 <- autoplot(fcast.nnetar.P8, include = 20) + ggtitle("")
   p9 <- autoplot(fcast.nnetar.P9, include = 20) + ggtitle("")
   grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, nrow = 3)
```

Assim como na seção anterior, aqui foram utilizados modelos NNETAR$(p,k)$, com $p=k=24$ para que esse seja capaz de capturar dinâmicas tais como possíveis sazonalidades anuais dos preços e não-linearidades e por fim, na tabela seguinte mostra-se uma avalição dos modelos a partir dos desvios padrões de seus resíduos.

\begin{center}
  \begin{tabular}{ c | c }
    Produto & NNETAR$(24,24)$                                \\ \hline\hline
    $P_1$   & $\widehat{\sigma_{e}} = 1,\!72 \times 10^{-3}$ \\  
    $P_2$   & $\widehat{\sigma_{e}} = 5,\!74 \times 10^{-3}$ \\
    $P_3$   & $\widehat{\sigma_{e}} = 5,\!79 \times 10^{-3}$ \\
    $P_4$   & $\widehat{\sigma_{e}} = 9,\!10 \times 10^{-3}$ \\
    $P_5$   & $\widehat{\sigma_{e}} = 2,\!97 \times 10^{-3}$ \\
    $P_6$   & $\widehat{\sigma_{e}} = 1,\!63 \times 10^{-2}$ \\
    $P_7$   & $\widehat{\sigma_{e}} = 1,\!05 \times 10^{-2}$ \\
    $P_8$   & $\widehat{\sigma_{e}} = 7,\!47 \times 10^{-3}$ \\
    $P_9$   & $\widehat{\sigma_{e}} = 8,\!28 \times 10^{-3}$ \\
  \end{tabular}
\end{center}

Portanto, comparando a última tabela com a última tabela da seção anterior é possível inferir que todos os modelos para os produtos da base de dados 'sales.csv' foram superiores, pois os desvios padrões dos resíduos dos modelos das previsões para os produtos ($P_i, i = 1, \cdots, 9$) foram menores para os da B2W do que os dos competidores.

Assim, o poder preditivo dos dados fornecidos para a B2W são superiores do que para os da competição.